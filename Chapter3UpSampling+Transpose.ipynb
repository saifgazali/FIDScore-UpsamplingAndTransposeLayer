{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image, in a one-shot manner.\n",
    "A traditional convolutional neural network for image classification, and related tasks, will\n",
    "use pooling layers to downsample input images. For example, an average pooling or max pooling\n",
    "layer will reduce the feature maps from a convolutional by half on each dimension, resulting\n",
    "in an output that is one quarter the area of the input. Convolutional layers themselves also\n",
    "perform a form of downsampling by applying each filter across the input images or feature maps;\n",
    "the resulting activations are an output feature map that is smaller because of the border effects.\n",
    "Often padding is used to counter this effect. The generator model in a GAN requires an inverse\n",
    "operation of a pooling layer in a traditional convolutional layer. It needs a layer to translate\n",
    "from coarse salient features to a more dense and detailed output.\n",
    "A simple version of an unpooling or opposite pooling layer is called an upsampling layer.\n",
    "It works by repeating the rows and columns of the input. A more elaborate approach is to\n",
    "perform a backwards convolutional operation, originally referred to as a deconvolution, which is\n",
    "incorrect, but is more commonly referred to as a fractional convolutional layer or a transposed\n",
    "convolutional layer. Both of these layers can be used on a GAN to perform the required\n",
    "upsampling operation to transform a small input into a large image output. In the following\n",
    "sections, we will take a closer look at each and develop an intuition for how they work so that\n",
    "we can use them effectively in our GAN mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "\n",
    "X = np.array([[1,2],[3,4]])\n",
    "\n",
    "# We must add a channel dimension (e.g. grayscale) and also a sample dimension (e.g. we have 1 sample) so that we can pass it as input to the model. The\n",
    "# data dimensions in order are: samples, rows, columns, and channels.\n",
    "\n",
    "X = X.reshape((1,2,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "up_sampling2d (UpSampling2D) (None, 4, 4, 1)           0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(UpSampling2D(input_shape=(2,2,1)))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.],\n",
       "         [1.],\n",
       "         [2.],\n",
       "         [2.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [2.],\n",
       "         [2.]],\n",
       "\n",
       "        [[3.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [4.]],\n",
       "\n",
       "        [[3.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [4.]]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the layer has no parameters or model weights. This is because it is not learning anything; it is just\n",
    "#doubling the input.\n",
    "yhat = model.predict(X)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 2. 2.]\n",
      " [1. 1. 2. 2.]\n",
      " [3. 3. 4. 4.]\n",
      " [3. 3. 4. 4.]]\n"
     ]
    }
   ],
   "source": [
    "#  reshape output to remove sample and channel to make printing easier\n",
    "yhat = yhat.reshape((4,4))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default, the UpSampling2D will double each input dimension. This is defined by the\n",
    "#size argument that is set to the tuple (2,2). You may want to use different factors on each\n",
    "#dimension, such as double the width and triple the height. This could be achieved by setting\n",
    "#the size argument to (2, 3)\n",
    "\n",
    "# example of using different scale factors for each dimension\n",
    "model.add(UpSampling2D(size=(2, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additionally, by default, the UpSampling2D layer will use a nearest neighbor algorithm to\n",
    "#fill in the new rows and columns. This has the effect of simply doubling rows and columns, as\n",
    "#described and is specified by the interpolation argument set to ‘nearest’. Alternately, a\n",
    "#bilinear interpolation method can be used which draws upon multiple surrounding points. This\n",
    "#can be specified via setting the interpolation argument to ‘bilinear’.\n",
    "\n",
    "\n",
    "model.add(UpSampling2D(interpolation='bilinear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 3200)              323200    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 1)         1153      \n",
      "=================================================================\n",
      "Total params: 324,353\n",
      "Trainable params: 324,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Simple Generator model with the upsampling2D layer \n",
    "\n",
    "# To be useful in a GAN, each UpSampling2D layer must be followed by a Conv2D layer that will learn to interpret the doubled\n",
    "# input and be trained to translate it into meaningful detail\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "# define input shape and enough activations for the 128 5x5 image\n",
    "model.add(Dense(128 * 5 * 5,input_dim=100))\n",
    "# reshape the vector of activation into 128 feature maps with 5x5\n",
    "model.add(Reshape((5,5,128)))\n",
    "#double the input from 128 5x5 to 1 10x10 feature map\n",
    "model.add(UpSampling2D())\n",
    "#fill in deatil in upsampled feature maps and output a single image\n",
    "model.add(Conv2D(1,(3,3),padding='same'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use a Transpose Convolutional Layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define our model. The model has only the Conv2DTranspose layer, which\n",
    "takes 2 × 2 grayscale images as input directly and outputs the result of the operation. The\n",
    "Conv2DTranspose both upsamples and performs a convolution. As such, we must specify both\n",
    "the number of filters and the size of the filters as we do for Conv2D layers. Additionally, we\n",
    "must specify a stride of (2,2) because the upsampling is achieved by the stride behavior of the\n",
    "convolution on the input. Specifying a stride of (2,2) has the effect of spacing out the input.\n",
    "Specifically, rows and columns of 0.0 values are inserted to achieve the desired stride. In this\n",
    "example, we will use one filter, with a 1 × 1 kernel and a stride of 2 × 2 so that the 2 × 2 input\n",
    "image is upsampled to 4 × 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose (Conv2DTran (None, 4, 4, 1)           2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "model = Sequential()\n",
    "model.add(Conv2DTranspose(1,(1,1),strides=(2,2),input_shape=(2,2,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now define our model. The model has only the Conv2DTranspose layer, which\n",
    "#takes 2 × 2 grayscale images as input directly and outputs the result of the operation. The\n",
    "#Conv2DTranspose both upsamples and performs a convolution. As such, we must specify both\n",
    "#the number of filters and the size of the filters as we do for Conv2D layers. Additionally, we\n",
    "#must specify a stride of (2,2) because the upsampling is achieved by the stride behavior of the\n",
    "#convolution on the input. Specifying a stride of (2,2) has the effect of spacing out the input.\n",
    "#Specifically, rows and columns of 0.0 values are inserted to achieve the desired stride. In this\n",
    "#example, we will use one filter, with a 1 × 1 kernel and a stride of 2 × 2 so that the 2 × 2 input\n",
    "#image is upsampled to 4 × 4.\n",
    "\n",
    "\n",
    "weights = [np.asarray([[[[1]]]]),np.asarray([0])]\n",
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 2. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [3. 0. 4. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "yhat = yhat.reshape((4,4))\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Conv2DTranspose is more complex than the UpSampling2D layer, but it is also effective\n",
    "when used in GAN models, specifically the generator model. Either approach can be used,\n",
    "although the Conv2DTranspose layer is preferred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our little GAN generator model must produce a 10 × 10 image and take a\n",
    "100-element vector from the latent space as input, as in the previous UpSampling2D example.\n",
    "First, a Dense fully connected layer can be used to interpret the input vector and create a\n",
    "sufficient number of activations (outputs) that can be reshaped into a low-resolution version of\n",
    "our output image, in this case, 128 versions of a 5 × 5 image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the 5 × 5 feature maps can be upsampled to a 10 × 10 feature map. We will use a\n",
    "3 × 3 kernel size for the single filter, which will result in a slightly larger than doubled width\n",
    "and height in the output feature map (11 × 11). Therefore, we will set the padding argument\n",
    "to ‘same’ to ensure the output dimensions are 10 × 10 as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 3200)              323200    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 10, 10, 1)         1153      \n",
      "=================================================================\n",
      "Total params: 324,353\n",
      "Trainable params: 324,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128*5*5,input_dim=100))\n",
    "model.add(Reshape((5,5,128)))\n",
    "model.add(Conv2DTranspose(1,(3,3),strides=(2,2),padding='same'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
